{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes Algorithm\n",
    "\n",
    "In this project, I will build a spam filter for SMS messages.\n",
    "\n",
    "To classify messages as spam or non-spam, the computer will:\n",
    "1. Learn how humans classify messages\n",
    "2. Use that knowledge to estimate spam and non-spam probabilities for new messages\n",
    "3. Classify a new message based on these probability values\n",
    "\n",
    "Our first task is to 'teach' the computer how to classify messages. To do that, we'll use the multinomial Naive Bayes algorithm along with a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by Tiago A. Almeida and José María Gómez Hidalgo, and can be downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). You can also download the dataset directly from [this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). The data collection process is described in more details on [this page](http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition).\n",
    "\n",
    "Let's start by reading in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "\n",
      "Spam:  747 \n",
      "Pct Spam:  13.41 % \n",
      "\n",
      "Non-spam:  4825 \n",
      "Pct non-spam:  86.59 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "messages = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "print(messages.shape)\n",
    "num_spam = len(messages[messages['Label'] == 'spam'])\n",
    "num_non_spam = len(messages[messages['Label'] == 'ham'])  # 'ham' means non-spam\n",
    "print('\\nSpam: ', num_spam, '\\nPct Spam: ', round(100 * num_spam / len(messages), 2), '%', \n",
    "      '\\n\\nNon-spam: ', num_non_spam, '\\nPct non-spam: ', round(100 * num_non_spam / len(messages), 2), '%')\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approx. 13% of messages are spam, and the remaining 87% are non-spam.\n",
    "\n",
    "Before creating the spam filter, I will first design the test.\n",
    "\n",
    "To test the spam filter, I will first split the dataset into two categories:\n",
    "- a **training set**, which will be used to train the computer how to classify messages\n",
    "- a **test set**, which will be used to test how good the spam filter is with classifying new messages\n",
    "\n",
    "We will keep 80% of our dataset for training (4,458 messages), and 20% for testing (1,114 messages). Since the 1,114 messages in the test set were already classified by a human, we can compare the algorithm classification with the human classification to see how well it works. Our goal is to create a spam filter that classifies new messages with an accuracy greater than 80%.\n",
    "\n",
    "I will start by creating the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (4458, 2) \n",
      "Test set shape:  (1114, 2)\n",
      "\n",
      "Training pct spam: 13.46%\n",
      "Training pct ham: 86.54%\n",
      "\n",
      "Test pct spam: 13.2%\n",
      "Test pct ham: 86.8%\n"
     ]
    }
   ],
   "source": [
    "# Randomize entire dataset:\n",
    "random = messages.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index to split on\n",
    "train_test_index = round(len(random) * .8)\n",
    "\n",
    "# Create training and test data sets\n",
    "training_set = random[:train_test_index].reset_index(drop=True)\n",
    "test_set = random[train_test_index:].reset_index(drop=True)\n",
    "\n",
    "print('Training set shape: ', training_set.shape, '\\nTest set shape: ', test_set.shape)\n",
    "\n",
    "# Find percentage of spam and ham in both training and test sets to ensure similar percentages to full dataset\n",
    "\n",
    "train_n_spam = len(training_set[training_set['Label'] == 'spam'])\n",
    "train_pct_spam = 100 * train_n_spam / len(training_set)\n",
    "\n",
    "train_n_ham = len(training_set[training_set['Label'] == 'ham'])\n",
    "train_pct_ham = 100 * train_n_ham / len(training_set)\n",
    "\n",
    "test_n_spam = len(test_set[test_set['Label'] == 'spam'])\n",
    "test_pct_spam = 100 * test_n_spam / len(test_set)\n",
    "\n",
    "test_n_ham = len(test_set[test_set['Label'] == 'ham'])\n",
    "test_pct_ham = 100 * test_n_ham / len(test_set)\n",
    "\n",
    "print('\\nTraining pct spam: {}%\\nTraining pct ham: {}%\\n\\nTest pct spam: {}%\\nTest pct ham: {}%'.format(\n",
    "round(train_pct_spam, 2), round(train_pct_ham, 2), round(test_pct_spam, 2), round(test_pct_ham, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both of the training and test sets conntain approx. 13% spam messages and 87% ham messages, which is the same as the original dataset. Thus, our training and test datasets will work well.\n",
    "\n",
    "The next step is to use the training set to teach the algorithm to classify new messages. \n",
    "\n",
    "When a new message comes in, our Naive Bayes algorithm will make the classification based on the results it gets to these two equations:\n",
    "\n",
    "P(Spam|w1,w2,...,wn) ∝ P(Spam)⋅∏P(wi|Spam)\n",
    "\n",
    "P(Ham|w1,w2,...,wn) ∝ P(Ham)⋅∏P(wi|Ham)\n",
    "\n",
    "Also, to calculate P(wi|Spam) and P(wi|Ham) inside the formulas above, we need to use these equations:\n",
    "\n",
    "P(wi|Spam) = (N(wi|Spam) + α) / (NSpam + α⋅NVocabulary)\n",
    "\n",
    "P(wi|Ham) = (N(wi|Ham) + α) / (NHam + α⋅NVocabulary)\n",
    "\n",
    "Let's also summarize what the terms in the equations above mean:\n",
    "\n",
    "- N(wi|Spam) = the number of times the word wi occurs in spam messages\n",
    "- N(wi|Ham) = the number of times the word wi occurs in non-spam messages\n",
    "- NSpam = total number of words in spam messages\n",
    "- NHam = total number of words in non-spam messages\n",
    "- NVocabulary = total number of words in the vocabulary\n",
    "- α = 1    (α is a smoothing parameter)\n",
    "\n",
    "To make the calculations easier, we will replace the SMS column with columns for each word in all of the messages, whos values are the number of times that word appeared in the SMS message.\n",
    "\n",
    "I will start this process by first removing the punctuation and bringing all words to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will now create a vocabulary for the messages in the training set, which is a set of all of the unique words in the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split() # split each of the messages into a list of words\n",
    "\n",
    "vocabulary = []\n",
    "for message in training_set['SMS']: # add each word to the vocabulary list\n",
    "    for word in message:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary)) # transform to a set to remove duplicates, then back to a list\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7783 unique words in the vocabulary\n",
    "\n",
    "Lets create a dictionary of each unique word and its count per sms, and then transform that into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize empry dictionary with each word having a 0 for each message in the training set\n",
    "word_counts_per_message = {word: [0] * len(training_set['SMS']) for word in vocabulary}\n",
    "\n",
    "# Iterate through each message, and get word counts\n",
    "for index, message in enumerate(training_set['SMS']):\n",
    "    for word in message:\n",
    "        word_counts_per_message[word][index] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>02072069400</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  000pes  008704050406  0089  01223585334  02  0207  02072069400  \\\n",
       "0  0   0    0       0             0     0            0   0     0            0   \n",
       "1  0   0    0       0             0     0            0   0     0            0   \n",
       "2  0   0    0       0             0     0            0   0     0            0   \n",
       "3  0   0    0       0             0     0            0   0     0            0   \n",
       "4  0   0    0       0             0     0            0   0     0            0   \n",
       "\n",
       "  ...  zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "1 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "2 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "3 ...       0    0          0     0      0  0   0  0    0  0  \n",
       "4 ...       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_message)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]  0   0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...  0   0    0   \n",
       "2   ham                    [welp, apparently, he, retired]  0   0    0   \n",
       "3   ham                                           [havent]  0   0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...  0   0    0   \n",
       "\n",
       "   000pes  008704050406  0089  01223585334  02 ...  zindgi  zoe  zogtorius  \\\n",
       "0       0             0     0            0   0 ...       0    0          0   \n",
       "1       0             0     0            0   0 ...       0    0          0   \n",
       "2       0             0     0            0   0 ...       0    0          0   \n",
       "3       0             0     0            0   0 ...       0    0          0   \n",
       "4       0             0     0            0   0 ...       0    0          0   \n",
       "\n",
       "   zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0     0      0  0   0  0    0  0  \n",
       "1     0      0  0   0  0    0  0  \n",
       "2     0      0  0   0  0    0  0  \n",
       "3     0      0  0   0  0    0  0  \n",
       "4     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating constants\n",
    "\n",
    "Now that we have our dataframe we want to work with, we'll begin by calculating P(Spam), P(Ham), NSpam, NHam, and NVocabulary.\n",
    "\n",
    "NSpam is equal to the number of words in all the spam messages, not the number of spam messages or number of unique words in spam messages\n",
    "NHam is equal to the number of words in all non-spam messages\n",
    "\n",
    "We'll also use Laplace smoothing and set α = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Isolate spam and ham messages\n",
    "spam = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# Calculate p_spam and p_ham\n",
    "p_spam = len(spam) / len(training_set_clean)\n",
    "p_ham = len(ham) / len(training_set_clean)\n",
    "\n",
    "# Calculate NSpam, NHam, and NVocabulary\n",
    "n_words_per_spam_message = spam['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "n_words_per_ham_message = ham['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "    \n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Parameters\n",
    "\n",
    "Our results will come from the equations:\n",
    "- P(Spam|w1,w2,...,wn) ∝ P(Spam)⋅∏P(wi|Spam)\n",
    "- P(Ham|w1,w2,...,wn) ∝ P(Ham)⋅∏P(wi|Ham)\n",
    "\n",
    "where \n",
    "- P(wi|Spam) = (N(wi|Spam) + α) / (NSpam + α⋅NVocabulary)\n",
    "- P(wi|Ham) = (N(wi|Ham) + α) / (NHam + α⋅NVocabulary)\n",
    "\n",
    "Let's calculate the parameters P(wi|Spam) and P(wi|Ham):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize empty dictionaries\n",
    "spam_param = {word: 0 for word in vocabulary}\n",
    "ham_param = {word: 0 for word in vocabulary}\n",
    "\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam[word].sum()\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "    spam_param[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham[word].sum()\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    ham_param[word] = p_word_given_ham\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the spam filter\n",
    "\n",
    "Now that we've calculated all the constants and parameters we need, we can start creating the spam filter, which will be a function that:\n",
    "- Takes in an input of a new message (w1, w2, ..., wn)\n",
    "- Calculates P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn)\n",
    "- Compares the values of P(Spam|w1, w2, ..., wn) and P(Ham|w1, w2, ..., wn) and:\n",
    "    - if P(Spam|w1, w2, ..., wn) < P(Ham|w1, w2, ..., wn), the message is classified as ham\n",
    "    - if P(Spam|w1, w2, ..., wn) > P(Ham|w1, w2, ..., wn), the message is classified as spam\n",
    "    - if P(Spam|w1, w2, ..., wn) = P(Ham|w1, w2, ..., wn), the algorithm may request human help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in spam_param:\n",
    "            p_spam_given_message *= spam_param[word]\n",
    "        if word in ham_param:\n",
    "            p_ham_given_message *= ham_param[word]\n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classify function appears to work well. We will now use it to test our set of 1,114 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new classify function that returns labels instead of printing them\n",
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in spam_param:\n",
    "            p_spam_given_message *= spam_param[word]\n",
    "        if word in ham_param:\n",
    "            p_ham_given_message *= ham_param[word]\n",
    "            \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  1100\n",
      "Incorrect 14\n",
      "Percent correct:  98.74 %\n"
     ]
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "\n",
    "test_set['correct'] = test_set['predicted'] == test_set['Label']\n",
    "correct=test_set['correct'].sum()\n",
    "total = len(test_set)        \n",
    "percent_correct = 100 * correct / total\n",
    "\n",
    "print('Correct: ', correct)\n",
    "print('Incorrect', total - correct)\n",
    "print('Percent correct: ', round(percent_correct, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We accurately predicted 98% of the labels!\n",
    "\n",
    "Let's look at the messages we didn't correctly predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>spam</td>\n",
       "      <td>Not heard from U4 a while. Call me now am here...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>ham</td>\n",
       "      <td>Unlimited texts. Limited minutes.</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nokia phone is lovly..</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ham</td>\n",
       "      <td>A Boy loved a gal. He propsd bt she didnt mind...</td>\n",
       "      <td>needs human classification</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>ham</td>\n",
       "      <td>No calls..messages..missed calls</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>spam</td>\n",
       "      <td>Oh my god! I've found your number again! I'm s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>spam</td>\n",
       "      <td>0A$NETWORKS allow companies to bill for SMS, s...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>spam</td>\n",
       "      <td>RCT' THNQ Adrian for U text. Rgds Vatian</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>spam</td>\n",
       "      <td>2/2 146tf150p</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello. We need some posh birds and chaps to us...</td>\n",
       "      <td>ham</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "114  spam  Not heard from U4 a while. Call me now am here...   \n",
       "135  spam  More people are dogging in your area now. Call...   \n",
       "152   ham                  Unlimited texts. Limited minutes.   \n",
       "159   ham                                       26th OF JULY   \n",
       "284   ham                             Nokia phone is lovly..   \n",
       "293   ham  A Boy loved a gal. He propsd bt she didnt mind...   \n",
       "302   ham                   No calls..messages..missed calls   \n",
       "319   ham  We have sent JD for Customer Service cum Accou...   \n",
       "504  spam  Oh my god! I've found your number again! I'm s...   \n",
       "546  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "741  spam  0A$NETWORKS allow companies to bill for SMS, s...   \n",
       "876  spam           RCT' THNQ Adrian for U text. Rgds Vatian   \n",
       "885  spam                                      2/2 146tf150p   \n",
       "953  spam  Hello. We need some posh birds and chaps to us...   \n",
       "\n",
       "                      predicted  correct  \n",
       "114                         ham    False  \n",
       "135                         ham    False  \n",
       "152                        spam    False  \n",
       "159                        spam    False  \n",
       "284                        spam    False  \n",
       "293  needs human classification    False  \n",
       "302                        spam    False  \n",
       "319                        spam    False  \n",
       "504                         ham    False  \n",
       "546                         ham    False  \n",
       "741                         ham    False  \n",
       "876                         ham    False  \n",
       "885                         ham    False  \n",
       "953                         ham    False  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[test_set['correct'] == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One of the predicted needed human classification.\n",
    "- Many of the spam messages incorrectly predicted as ham sound like ham and I am unsurprised the computer predicted ham\n",
    "- Many of the ham messages incorrectly predicted as spam contained words that sound sort of 'spammy'\n",
    "\n",
    "Overall, it appears that our spam filter works very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
